# LLM_1B_7B-experiment_inference
Try out various LLM 1B & 7B parameter models in experiments. Finally, we'll perform real-time inference on Colab GPU using Text-Generation-Inference.
